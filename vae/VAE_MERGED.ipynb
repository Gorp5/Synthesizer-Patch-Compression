{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ba95a4",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "id": "7884b542",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5c9f4920-8c08-42c9-a517-c376d5f1e1b5",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "LATENT_DIM = 16\n",
    "BATCH_SIZE = 2048\n",
    "EPOCHS = 1000\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "GRADIENT_CLIPPING = False\n",
    "CLIP_VALUE = 100\n",
    "STD_DEV_MEASURE_MOD = 50\n",
    "STD_DEV_MEASURE_SCALE = 1\n",
    "LOSS_REDUCTION = \"mean\"    # sum or mean\n",
    "\n",
    "TRAIN_RATIO = 0.8"
   ],
   "id": "450cdd35650dddd2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bb536d5e-ac6c-4cd5-aaad-811a71c31ac7",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from data_processing import PatchProcessor\n",
    "import data_processing\n",
    "params = data_processing.get_params()\n",
    "processor = PatchProcessor(params)\n",
    "\n",
    "df = pd.read_csv(\"E:\\\\Coding\\\\vae-main\\\\old\\\\dx7_cleaned.csv\")\n",
    "df = df.drop(columns=df.columns[0])\n",
    "\n",
    "df = processor.normalize(df)\n",
    "df_encoded, expanded_types = processor.one_hot_dataframe(df)\n",
    "\n",
    "mse_mask, be_mask, ce_mask, alg_mask = processor.make_masks(expanded_types)\n",
    "masks = (mse_mask, be_mask, ce_mask, alg_mask)\n",
    "algorithms, alibi_distances = data_processing.get_algorithms()\n",
    "\n",
    "encoded_data_array = df_encoded.to_numpy()\n",
    "x_data = torch.tensor(encoded_data_array, dtype=torch.float32)\n",
    "dataset = torch.utils.data.TensorDataset(x_data)"
   ],
   "id": "7c2f28ffaf757236",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "12be9613-228e-49c5-9ad5-a05d3320c169",
   "metadata": {},
   "source": [
    "import os\n",
    "from helpers import *\n",
    "\n",
    "mse_loss = nn.MSELoss(reduction=LOSS_REDUCTION)\n",
    "bce_loss = nn.BCELoss(reduction=LOSS_REDUCTION)\n",
    "ce_loss = nn.CrossEntropyLoss(reduction=LOSS_REDUCTION)\n",
    "algo_loss = nn.CrossEntropyLoss(reduction=LOSS_REDUCTION)\n",
    "\n",
    "def latent_display(model, name):\n",
    "    train_dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    visualize_latent_space(model, dataloader=train_dataloader, device=\"cuda\", NAME=name)\n",
    "\n",
    "def model_size(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    return params\n",
    "\n",
    "def warmup(epoch, max_epoch, rate, max_beta):\n",
    "    y = min(rate * epoch, rate * max_epoch)\n",
    "    y = min(y, max_beta)\n",
    "    return y\n",
    "\n",
    "def cyclic_beta_schedule(epoch, max_beta, period=100):\n",
    "    # see: https://www.microsoft.com/en-us/research/blog/less-pain-more-gain-a-simple-method-for-vae-training-with-less-of-that-kl-vanishing-agony/\n",
    "    half_period = period // 2\n",
    "    i = epoch % period\n",
    "     # hold at max for last half of period\n",
    "    if i > half_period: return max_beta       \n",
    "     # grow to max for first half of period\n",
    "    return i / half_period * max_beta\n",
    "    \n",
    "def train_model(vae, masks, train_dataloader, val_dataloader, device, debug=False):\n",
    "    mse_mask, be_mask, ce_mask, alg_mask = masks\n",
    "\n",
    "    # register hook for gradient clipping\n",
    "    if GRADIENT_CLIPPING:\n",
    "        for param in vae.parameters():\n",
    "            param.register_hook(lambda grad: torch.clamp(grad, -CLIP_VALUE, CLIP_VALUE))\n",
    "    \n",
    "    # use AdamW instead as Adam is broken\n",
    "    optimizer = torch.optim.AdamW(vae.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=LEARNING_RATE,\n",
    "        pct_start=0.0,\n",
    "        steps_per_epoch=len(train_dataloader),\n",
    "        epochs=EPOCHS\n",
    "    )\n",
    "    \n",
    "    train_losses, train_mse_recon_losses, train_ce_recon_losses, train_kl_losses, train_be_recon_losses, train_algo_recon_losses  = [], [], [], [], [], []\n",
    "    val_losses, val_mse_recon_losses, val_ce_recon_losses, val_kl_losses, val_be_recon_losses, val_algo_recon_losses = [], [], [], [], [], []\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        start_time = time.time()\n",
    "        train_epoch_total_loss = 0\n",
    "        train_epoch_mse_recon_loss = 0\n",
    "        train_epoch_ce_recon_loss = 0\n",
    "        train_epoch_be_recon_loss = 0\n",
    "        train_epoch_kl_loss = 0\n",
    "        train_sparsity_loss = 0\n",
    "        train_epoch_algo_loss = 0\n",
    "        train_total_mse_loss = 0\n",
    "\n",
    "        val_epoch_total_loss = 0\n",
    "        val_epoch_mse_recon_loss = 0\n",
    "        val_epoch_ce_recon_loss = 0\n",
    "        val_epoch_be_recon_loss = 0\n",
    "        val_epoch_kl_loss = 0\n",
    "        val_epoch_sparsity_loss = 0\n",
    "        val_epoch_algo_loss = 0\n",
    "        val_total_mse_loss = 0\n",
    "        if epoch % STD_DEV_MEASURE_MOD == 0:\n",
    "            plt.clf()\n",
    "            \n",
    "        beta = cyclic_beta_schedule(epoch, BETA, period=(EPOCHS // BETA_CYCLES))\n",
    "\n",
    "        vae.train()\n",
    "        for batch in train_dataloader:\n",
    "            x_batch = batch[0].to(device)\n",
    "            \n",
    "            recon_x, mu, logvar, sparse_loss = vae(x_batch)\n",
    "\n",
    "            train_total_loss, train_mse_recon_loss, train_ce_recon_loss, train_be_recon_loss, train_kl_loss, total_mse, alg_loss = vae_total_loss(\n",
    "                recon_x,\n",
    "                x_batch,\n",
    "                be_mask,\n",
    "                ce_mask,\n",
    "                mse_mask,\n",
    "                alg_mask,\n",
    "                mu,\n",
    "                logvar,\n",
    "                beta\n",
    "            )\n",
    "\n",
    "            #train_total_loss += sparse_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            train_total_loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            train_epoch_total_loss += train_total_loss.item()\n",
    "            train_epoch_mse_recon_loss += train_mse_recon_loss.item()\n",
    "            train_epoch_ce_recon_loss += train_ce_recon_loss.item()\n",
    "            train_epoch_be_recon_loss += train_be_recon_loss.item()\n",
    "            train_epoch_kl_loss += train_kl_loss.item()\n",
    "            train_epoch_algo_loss += alg_loss.item()\n",
    "            #train_sparsity_loss += sparse_loss\n",
    "            train_total_mse_loss += total_mse.item()\n",
    "\n",
    "        vae.eval() # <- mode for just evaluating\n",
    "        with torch.no_grad(): # <- don't track gradients\n",
    "            for batch in val_dataloader:\n",
    "                x_batch = batch[0].to(device)\n",
    "                recon_x, mu, logvar, sparse_loss = vae(x_batch)\n",
    "                val_total_loss, val_mse_recon_loss, val_ce_recon_loss, val_be_recon_loss, val_kl_loss, val_mse_total, alg_loss = vae_total_loss(\n",
    "                    recon_x,\n",
    "                    x_batch,\n",
    "                    be_mask,\n",
    "                    ce_mask,\n",
    "                    mse_mask,\n",
    "                    alg_mask,\n",
    "                    mu,\n",
    "                    logvar,\n",
    "                    beta,\n",
    "                )\n",
    "\n",
    "                #val_total_loss += sparse_loss\n",
    "\n",
    "                val_epoch_total_loss += val_total_loss.item()\n",
    "                val_epoch_mse_recon_loss += val_mse_recon_loss.item()\n",
    "                val_epoch_ce_recon_loss += val_ce_recon_loss.item()\n",
    "                val_epoch_be_recon_loss += val_be_recon_loss.item()\n",
    "                val_epoch_kl_loss += val_kl_loss.item()\n",
    "                val_total_mse_loss += val_mse_total.item()\n",
    "                val_epoch_algo_loss += alg_loss.item()\n",
    "                #val_epoch_sparsity_loss += sparse_loss\n",
    "\n",
    "        if epoch % STD_DEV_MEASURE_MOD == 0:\n",
    "            plt.savefig(f\"graph/outputs_{epoch//STD_DEV_MEASURE_MOD:08d}.png\")\n",
    "\n",
    "        train_avg_total_loss = train_epoch_total_loss           / len(train_dataloader)\n",
    "        train_avg_mse_recon_loss = train_epoch_mse_recon_loss   / len(train_dataloader)\n",
    "        train_avg_ce_recon_loss = train_epoch_ce_recon_loss     / len(train_dataloader)\n",
    "        train_avg_be_recon_loss = train_epoch_be_recon_loss     / len(train_dataloader)\n",
    "        train_avg_kl_loss = train_epoch_kl_loss                 / len(train_dataloader)\n",
    "        train_avg_algo_loss = train_epoch_algo_loss             / len(train_dataloader)\n",
    "        #train_avg_sparsity_loss = train_sparsity_loss           / len(train_dataloader)\n",
    "        train_avg_epoch_mse_loss = train_total_mse_loss         / len(train_dataloader)\n",
    "\n",
    "        train_losses.append(train_avg_total_loss)\n",
    "        train_mse_recon_losses.append(train_avg_mse_recon_loss)\n",
    "        train_ce_recon_losses.append(train_avg_ce_recon_loss)\n",
    "        train_be_recon_losses.append(train_avg_be_recon_loss)\n",
    "        train_algo_recon_losses.append(train_avg_algo_loss)\n",
    "\n",
    "        train_kl_losses.append(train_avg_kl_loss)\n",
    "\n",
    "        val_avg_total_loss = val_epoch_total_loss               / len(val_dataloader)\n",
    "        val_avg_mse_recon_loss = val_epoch_mse_recon_loss       / len(val_dataloader)\n",
    "        val_avg_ce_recon_loss = val_epoch_ce_recon_loss         / len(val_dataloader)\n",
    "        val_avg_be_recon_loss = val_epoch_be_recon_loss         / len(val_dataloader)\n",
    "        val_avg_kl_loss = val_epoch_kl_loss                     / len(val_dataloader)\n",
    "        val_avg_algo_loss = val_epoch_algo_loss                 / len(val_dataloader)\n",
    "        #val_avg_sparsity_loss = val_epoch_sparsity_loss         / len(val_dataloader)\n",
    "        val_avg_epoch_mse_loss = val_total_mse_loss             / len(val_dataloader)\n",
    "\n",
    "        val_losses.append(val_avg_total_loss)\n",
    "        val_mse_recon_losses.append(val_avg_mse_recon_loss)\n",
    "        val_ce_recon_losses.append(val_avg_ce_recon_loss)\n",
    "        val_be_recon_losses.append(val_avg_be_recon_loss)\n",
    "        val_algo_recon_losses.append(val_avg_algo_loss)\n",
    "        val_kl_losses.append(val_avg_kl_loss)\n",
    "\n",
    "        end_time = time.time()\n",
    "        runtime = end_time - start_time\n",
    "        \n",
    "        if debug:\n",
    "            print(\"-\" * 50)\n",
    "            print(f\"Epoch {epoch+1}/{EPOCHS} done in {runtime:.4f} seconds\")\n",
    "            print(f\"Beta: {beta:.4f}\")\n",
    "            print(f\"Learning Rate: {scheduler.get_last_lr()[0]:.8f}\")\n",
    "            \n",
    "            print(f\"Training Loss: {train_avg_total_loss:.4f}\")\n",
    "            print(f\"\\tTraining MSE Reconstruction Loss: {train_avg_mse_recon_loss:.4f}\")\n",
    "            print(f\"\\tTraining CE Reconstruction Loss: {train_avg_ce_recon_loss:.4f}\")\n",
    "            print(f\"\\tTraining BE Reconstruction Loss: {train_avg_be_recon_loss:.4f}\")\n",
    "            print(f\"\\tTraining Algorithm Loss: {train_avg_algo_loss:.4f}\")\n",
    "            print(f\"\\tTraining KL Loss: {train_avg_kl_loss:.4f}\")\n",
    "            #print(f\"\\tTraining Sparsity Loss: {train_avg_sparsity_loss:.4f}\")\n",
    "            print(f\"\\tTraining Total MSE Reconstruction Loss: {train_avg_epoch_mse_loss:.4f}\")\n",
    "\n",
    "            print(f\"Validation Loss: {val_avg_total_loss:.4f}\")\n",
    "            print(f\"\\tValidation MSE Reconstruction Loss: {val_avg_mse_recon_loss:.4f}\")\n",
    "            print(f\"\\tValidation CE Reconstruction Loss: {val_avg_ce_recon_loss:.4f}\")\n",
    "            print(f\"\\tValidation BE Reconstruction Loss: {val_avg_be_recon_loss:.4f}\")\n",
    "            print(f\"\\tValidation Algorithm Loss: {val_avg_algo_loss:.4f}\")\n",
    "            print(f\"\\tValidation KL Loss: {val_avg_kl_loss:.4f}\")\n",
    "            #print(f\"\\tValidation Sparsity Loss: {val_avg_sparsity_loss:.4f}\")\n",
    "            print(f\"\\tValidation Total MSE Reconstruction Loss: {val_avg_epoch_mse_loss:.4f}\")\n",
    "\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "    return vae, train_losses, train_mse_recon_losses, train_ce_recon_losses, train_kl_losses, train_be_recon_losses, train_algo_recon_losses, val_losses, val_mse_recon_losses, val_ce_recon_losses, val_be_recon_losses, val_kl_losses, val_algo_recon_losses\n",
    "\n",
    "def train_loop(model):\n",
    "    # determine device\n",
    "    has_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if has_cuda else \"cpu\")\n",
    "    if has_cuda:\n",
    "        print(\"Using GPU\")\n",
    "    else:\n",
    "        print(\"Using CPU\")\n",
    "\n",
    "    train_data_count = round(len(dataset) * TRAIN_RATIO)\n",
    "    val_data_count = len(dataset) - train_data_count\n",
    "\n",
    "    print(\"Total samples:\", len(dataset))\n",
    "    print(\"Training samples:\", train_data_count)\n",
    "    print(\"Validation samples:\", val_data_count)\n",
    "\n",
    "    train_data, val_data = torch.utils.data.random_split(dataset, [train_data_count, val_data_count])\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    model.to(device=device)\n",
    "\n",
    "    print(f\"{model_size(model)} Parameters\")\n",
    "\n",
    "    # train vae\n",
    "    print(\"Training VAE...\")\n",
    "    vae, train_losses, train_mse_recon_losses, train_ce_recon_losses, train_kl_losses, train_be_recon_losses, train_algo_recon_losses, val_losses, val_mse_recon_losses, val_ce_recon_losses, val_be_recon_losses, val_kl_losses, val_algo_recon_loss = train_model(model, masks, train_dataloader, val_dataloader, device, debug=True)\n",
    "    print(\"VAE complete.\")\n",
    "\n",
    "    # visualize results\n",
    "    print(\"Plotting loss and UMAP of latent space...\")\n",
    "    os.makedirs(NAME, exist_ok=True)\n",
    "    plot_loss(train_losses, train_mse_recon_losses, train_ce_recon_losses, train_kl_losses, train_be_recon_losses, train_algo_recon_losses, val_losses, val_mse_recon_losses, val_ce_recon_losses, val_be_recon_losses, val_algo_recon_loss, val_kl_losses, NAME)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    visualize_latent_space(model, dataloader=train_dataloader, device=\"cuda\", NAME=NAME)(model, NAME)\n",
    "\n",
    "    # save the vae parameters\n",
    "    torch.save(vae.state_dict(), \"./models/\" + NAME + \"/model.pth\")\n",
    "    torch.save(vae, \"./models/\" + NAME + \"/model.model\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7a27fcfb-b4f0-4f41-bd5d-fbeca54028d1",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "NAME = \"GraphTransformer-Alibi-Full-Beta-0-001\"\n",
    "LATENT_DIM = 16\n",
    "BATCH_SIZE = 2048\n",
    "EPOCHS = 1000\n",
    "LEARNING_RATE = 1e-4\n",
    "BETA = 0.001\n",
    "WEIGHT_DECAY = 1e-5\n",
    "GRADIENT_CLIPPING = False\n",
    "CLIP_VALUE = 100\n",
    "STD_DEV_MEASURE_MOD = 50\n",
    "\n",
    "STD_DEV_MEASURE_SCALE = 1\n",
    "LOSS_REDUCTION = \"mean\"\n",
    "\n",
    "BETA_CYCLES = 10\n",
    "\n",
    "from GraphTransformerAlibiGlobalToken import GraphTransformerAutoencoderAlibi\n",
    "model = GraphTransformerAutoencoderAlibi(input_size=21, latent_space=LATENT_DIM, d_model=128, depth=6, heads=4, mlp_dim=256, num_algorithms=32, num_global_params=67, sparsity_weight=1, reparameterization=True, algorithm_distance_matricies=alibi_distances)\n",
    "\n",
    "train_loop(model)"
   ],
   "id": "6041b5bd66020527",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "NAME = \"GraphTransformer-Alibi-Full-Beta-0-01\"\n",
    "BETA = 0.01\n",
    "BATCH_SIZE = 2048\n",
    "LATENT_DIM = 16\n",
    "from GraphTransformerAlibiGlobalToken import GraphTransformerAutoencoderAlibi\n",
    "model = GraphTransformerAutoencoderAlibi(input_size=21, latent_space=LATENT_DIM, d_model=128, depth=6, heads=4, mlp_dim=256, num_algorithms=32, num_global_params=67, sparsity_weight=1, reparameterization=True, algorithm_distance_matricies=alibi_distances)\n",
    "train_loop(model)"
   ],
   "id": "3368d03d0a8b1eb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "NAME = \"GraphTransformer-Alibi-Full-Beta-0-1\"\n",
    "BETA = 0.1\n",
    "BATCH_SIZE = 2048\n",
    "LATENT_DIM = 16\n",
    "from GraphTransformerAlibiGlobalToken import GraphTransformerAutoencoderAlibi\n",
    "model = GraphTransformerAutoencoderAlibi(input_size=21, latent_space=LATENT_DIM, d_model=128, depth=6, heads=4, mlp_dim=256, num_algorithms=32, num_global_params=67, sparsity_weight=1, reparameterization=True, algorithm_distance_matricies=alibi_distances)\n",
    "train_loop(model)"
   ],
   "id": "8d7ac9cb29f6e924",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "NAME = \"GraphTransformer-Alibi-Full-Beta-0-25\"\n",
    "BETA = 0.25\n",
    "BATCH_SIZE = 2048\n",
    "LATENT_DIM = 16\n",
    "from GraphTransformerAlibiGlobalToken import GraphTransformerAutoencoderAlibi\n",
    "model = GraphTransformerAutoencoderAlibi(input_size=21, latent_space=LATENT_DIM, d_model=128, depth=6, heads=4, mlp_dim=256, num_algorithms=32, num_global_params=67, sparsity_weight=1, reparameterization=True, algorithm_distance_matricies=alibi_distances)\n",
    "train_loop(model)"
   ],
   "id": "64b1883bcf86b4f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_loop(model)\n",
    "NAME = \"GraphTransformer-Alibi-Full-Beta-0-3725\"\n",
    "BETA = 0.3725\n",
    "BATCH_SIZE = 2048\n",
    "LATENT_DIM = 16\n",
    "from GraphTransformerAlibiGlobalToken import GraphTransformerAutoencoderAlibi\n",
    "\n",
    "model = GraphTransformerAutoencoderAlibi(input_size=21, latent_space=LATENT_DIM, d_model=128, depth=6, heads=4,\n",
    "                                         mlp_dim=256, num_algorithms=32, num_global_params=67, sparsity_weight=1,\n",
    "                                         reparameterization=True, algorithm_distance_matricies=alibi_distances)\n",
    "train_loop(model)"
   ],
   "id": "ea72eb5b3c9739be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "NAME = \"GraphTransformer-Alibi-Full-Beta-0-5\"\n",
    "BETA = 0.5\n",
    "BATCH_SIZE = 2048\n",
    "LATENT_DIM = 16\n",
    "from GraphTransformerAlibiGlobalToken import GraphTransformerAutoencoderAlibi\n",
    "model = GraphTransformerAutoencoderAlibi(input_size=21, latent_space=LATENT_DIM, d_model=128, depth=6, heads=4, mlp_dim=256, num_algorithms=32, num_global_params=67, sparsity_weight=1, reparameterization=True, algorithm_distance_matricies=alibi_distances)\n",
    "train_loop(model)"
   ],
   "id": "6b62a2fed6c7c183",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "NAME = \"GraphTransformer-Alibi-Full-Beta-1\"\n",
    "BETA = 1\n",
    "BATCH_SIZE = 2048\n",
    "LATENT_DIM = 16\n",
    "from GraphTransformerAlibiGlobalToken import GraphTransformerAutoencoderAlibi\n",
    "model = GraphTransformerAutoencoderAlibi(input_size=21, latent_space=LATENT_DIM, d_model=128, depth=6, heads=4, mlp_dim=256, num_algorithms=32, num_global_params=67, sparsity_weight=1, reparameterization=True, algorithm_distance_matricies=alibi_distances)\n",
    "train_loop(model)"
   ],
   "id": "8d514c436eeb3a21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from ResidualNet import VariationalAutoencoder\n",
    "\n",
    "LATENT_DIM = 16\n",
    "BATCH_SIZE = 2048\n",
    "EPOCHS = 1000\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "WEIGHT_DECAY = 1e-5\n",
    "GRADIENT_CLIPPING = False\n",
    "CLIP_VALUE = 100\n",
    "STD_DEV_MEASURE_MOD = 50\n",
    "\n",
    "STD_DEV_MEASURE_SCALE = 1\n",
    "LOSS_REDUCTION = \"mean\"\n",
    "\n",
    "BETA_CYCLES = 10\n",
    "BETA = 0.001\n",
    "\n",
    "NAME = f\"VAE-{LATENT_DIM}-Beta-0-001\"\n",
    "\n",
    "model = VariationalAutoencoder(input_dim=225, output_dim=225, latent_dim=LATENT_DIM)\n",
    "train_loop(model)"
   ],
   "id": "7af6abe95aa1c99f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dx7 midi manual\n",
    "f0\n",
    "id\n",
    "stuff\n",
    "f7\n",
    "\n",
    "Euclidean Drum Patterns\n",
    "Conan Networks"
   ],
   "id": "811d4f66d0f2384f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from ResidualNet import VariationalAutoencoder\n",
    "\n",
    "BETA = 0.001\n",
    "NAME = f\"VAE-{LATENT_DIM}-Beta-0-001\"\n",
    "model = VariationalAutoencoder(input_dim=225, output_dim=225, latent_dim=LATENT_DIM)\n",
    "train_loop(model)"
   ],
   "id": "c34796d922d023ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from ResidualNet import VariationalAutoencoder\n",
    "BETA = 0.01\n",
    "NAME = f\"VAE-{LATENT_DIM}-Beta-0-01\"\n",
    "model = VariationalAutoencoder(input_dim=225, output_dim=225, latent_dim=LATENT_DIM)\n",
    "train_loop(model)"
   ],
   "id": "9f8bdd4f3d4d6c99",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "BETA = 0.1\n",
    "NAME = f\"VAE-{LATENT_DIM}-Beta-0-1\"\n",
    "model = VariationalAutoencoder(input_dim=225, output_dim=225, latent_dim=LATENT_DIM)\n",
    "train_loop(model)"
   ],
   "id": "67ceb70d0a4c0ade",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "BETA = 0.5\n",
    "NAME = f\"VAE-{LATENT_DIM}-Beta-0-5\"\n",
    "model = VariationalAutoencoder(input_dim=225, output_dim=225, latent_dim=LATENT_DIM)\n",
    "train_loop(model)"
   ],
   "id": "fb9a2223b292d46f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "BETA = 1\n",
    "NAME = f\"VAE-{LATENT_DIM}-Beta-1\"\n",
    "model = VariationalAutoencoder(input_dim=225, output_dim=225, latent_dim=LATENT_DIM)\n",
    "train_loop(model)"
   ],
   "id": "5fc9d3d676c02038",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6d763e097e6ab0af",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
